{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "448cc226",
   "metadata": {
    "tags": [
     "parameters"
    ]
   },
   "outputs": [],
   "source": [
    "params = {\n",
    "    \"input_files\": {\n",
    "        \"praise_data\": \"./praise.csv\",\n",
    "        \"rewardboard_list\": \"./rewardboard.csv\"\n",
    "      },\n",
    "      \"total_tokens_allocated\": 1000,\n",
    "      \"payout_token\": {\n",
    "        \"token_name\": \"GIV\",\n",
    "        \"token_address\": \"0x4f4f9b8d5b4d0dc10506e5551b0513b61fd59e75\"\n",
    "      },\n",
    "      \"token_reward_percentages\": {\n",
    "        \"contributor_rewards\": 0.871067,\n",
    "        \"quantifier_rewards\": 0.090324,\n",
    "        \"rewardboard_rewards\": 0.038608,\n",
    "        \"_comment\": \"These percentages are tweaked so a regular praise+sourcecred allocation amounts to 7% of total rewards to quantfiers and 3% to the rewardboard.\"\n",
    "      },\n",
    "      \"quantification_settings\": {\n",
    "        \"number_of_quantifiers_per_praise_receiver\": 4,\n",
    "        \"praise_quantify_allowed_values\": [\n",
    "          0, 1, 3, 5, 8, 13, 21, 34, 55, 89, 144\n",
    "        ],\n",
    "        \"praise_quantify_receiver_prseudonyms\": False,\n",
    "        \"praise_quantify_duplicate_praise_valuation\": 0.1\n",
    "      }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "careful-unemployment",
   "metadata": {
    "scrolled": true,
    "tags": [
     "hide_input"
    ]
   },
   "outputs": [],
   "source": [
    "\n",
    "import os\n",
    "import sys\n",
    "\n",
    "import math\n",
    "import pandas as pd \n",
    "import numpy as np \n",
    "\n",
    "import scrapbook as sb\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a698c34",
   "metadata": {},
   "outputs": [],
   "source": [
    "PRAISE_DATA_PATH = input_files[\"praise_data\"]\n",
    "REWARD_BOARD_ADDRESSES_PATH = input_files[\"rewardboard_list\"]\n",
    "\n",
    "praise_data = pd.read_csv(PRAISE_DATA_PATH)\n",
    "praise_data.columns = praise_data.columns.str.upper()\n",
    "\n",
    "rewardboard_addresses = pd.read_csv(REWARD_BOARD_ADDRESSES_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "nominated-monday",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "try:\n",
    "    CUTOFF_VALUE = token_reward_percentages[\"ceiling_cutoff\"]\n",
    "except:\n",
    "    #always distribute total amount of allocated tokens\n",
    "    CUTOFF_VALUE = 1 \n",
    "\n",
    "#if the amount of praise is below the cutoff, adapt number of distributed tokens\n",
    "if(len(praise_data.index) < CUTOFF_VALUE):\n",
    "        total_tokens_allocated = len(praise_data.index) / CUTOFF_VALUE * float(total_tokens_allocated)\n",
    "\n",
    "\n",
    "\n",
    "NUMBER_OF_PRAISE_REWARD_TOKENS_TO_DISTRIBUTE = math.trunc( float(total_tokens_allocated) * token_reward_percentages[\"contributor_rewards\"]*1000000) / 1000000\n",
    "NUMBER_OF_REWARD_TOKENS_FOR_QUANTIFIERS = math.trunc(  float(total_tokens_allocated) * token_reward_percentages[\"quantifier_rewards\"]*1000000) / 1000000\n",
    "NUMBER_OF_REWARD_TOKENS_FOR_REWARD_BOARD = math.trunc(  float(total_tokens_allocated) * token_reward_percentages[\"rewardboard_rewards\"]*1000000) / 1000000\n",
    "NUMBER_OF_QUANTIFIERS_PER_PRAISE = quantification_settings[\"number_of_quantifiers_per_praise_receiver\"]\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "rising-organizer",
   "metadata": {},
   "source": [
    "## Reward allocation\n",
    "\n",
    "### Praise\n",
    "\n",
    "This method allocates the praise rewards in a very straightforward way: It adds the value of all dished praised together, and then assigns to each user their % of the total."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "instructional-rotation",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def calc_praise_rewards(praiseData, tokensToDistribute):\n",
    "\n",
    "    totalPraisePoints = praiseData['AVG SCORE'].sum()\n",
    "\n",
    "    praiseData['PERCENTAGE'] = praiseData['AVG SCORE']/totalPraisePoints\n",
    "    praiseData['TOKEN TO RECEIVE'] = praiseData['PERCENTAGE'] * tokensToDistribute\n",
    "\n",
    "    return praiseData\n",
    "\n",
    "praise_distribution = calc_praise_rewards(praise_data.copy(), NUMBER_OF_PRAISE_REWARD_TOKENS_TO_DISTRIBUTE)\n",
    "praise_distribution.style\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "productive-trash",
   "metadata": {},
   "source": [
    "### SourceCred\n",
    "For now Sourcecred does the distribution independently, but if this changed we would calculate the rewards in the same way."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "tamil-boutique",
   "metadata": {},
   "source": [
    "## Preparing and combining the Datasets\n",
    "\n",
    "Now that we have both distributions, we can combine them into one table.\n",
    "But before that, we need to prepare the data and clean it a bit. We also use the chance to generate a table which shows us how much praise each user received. We'll use it later in our analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "molecular-indonesia",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\n",
    "#General Helper func. Puts all the \"processing we probably won't need to do later or do differently\" in one place\n",
    "#  -removes the '#' and following from discord names\n",
    "#  -Some renaming and dropping \n",
    "def prepare_praise(praise_data):\n",
    "\n",
    "    praise_data.rename(columns = {'TO USER ACCOUNT':'USER IDENTITY'}, inplace = True)\n",
    "    praise_data.rename(columns = {'TO ETH ADDRESS':'USER ADDRESS'}, inplace = True)\n",
    "    praise_data['USER ADDRESS'].fillna('MISSING USER ADDRESS', inplace=True)\n",
    "    \n",
    "    processed_praise = praise_data[['USER IDENTITY', 'USER ADDRESS', 'PERCENTAGE', 'TOKEN TO RECEIVE']]\n",
    "    praise_by_user = praise_data[['USER IDENTITY', 'USER ADDRESS', 'AVG SCORE', 'PERCENTAGE', 'TOKEN TO RECEIVE']].copy().groupby(['USER IDENTITY', 'USER ADDRESS']).agg('sum').reset_index()\n",
    "    \n",
    "    return processed_praise, praise_by_user\n",
    "\n",
    "\n",
    "processed_praise, praise_by_user = prepare_praise(praise_distribution.copy())\n",
    "processed_praise.style\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "unknown-crime",
   "metadata": {},
   "source": [
    "Let's also create a table which will let us focus on the quantifiers. It will show us what value each quantifier gave to each single praise item."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "statistical-premiere",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "def data_by_quantifier(praise_data):\n",
    "    quant_only = pd.DataFrame()\n",
    "    #praise_data.drop(['DATE', 'TO USER ACCOUNT', 'TO USER ACCOUNT ID', 'TO ETH ADDRESS', 'FROM USER ACCOUNT', 'FROM USER ACCOUNT ID', 'FROM ETH ADDRESS', 'REASON', 'SOURCE ID', 'SOURCE NAME', 'AVG SCORE'], axis=1, inplace=True)\n",
    "    num_of_quants = NUMBER_OF_QUANTIFIERS_PER_PRAISE\n",
    "    for i in range(num_of_quants):\n",
    "        q_name =  str( 'QUANTIFIER '+ str(i+1) +' USERNAME' )\n",
    "        q_addr =  str( 'QUANTIFIER '+ str(i+1) +' ETH ADDRESS')\n",
    "        q_value = str('SCORE '+str(i+1) )\n",
    "        q_duplicate = str('DUPLICATE ID '+str(i+1) )\n",
    "        \n",
    "        buf = praise_data[['ID', q_name , q_addr, q_value, q_duplicate]].copy()\n",
    "\n",
    "        #delete the duplicated rows\n",
    "        buf = buf.loc[buf[q_duplicate].isnull()] # only include the non-duplicated rows\n",
    "        buf = buf[['ID', q_name , q_addr, q_value]] # don't need the duplication info anymore\n",
    "        \n",
    "    \n",
    "        buf.rename(columns={q_name: 'QUANT_ID', q_addr: 'QUANT_ADDRESS', q_value: 'QUANT_VALUE', 'ID':'PRAISE_ID'}, inplace=True)\n",
    "\n",
    "        quant_only = quant_only.append(buf.copy(), ignore_index=True)\n",
    "\n",
    "    columnsTitles = ['QUANT_ID', 'QUANT_ADDRESS', 'PRAISE_ID', 'QUANT_VALUE']\n",
    "    quant_only.sort_values(['QUANT_ID', 'PRAISE_ID'], inplace=True)\n",
    "    quant_only =  quant_only.reindex(columns=columnsTitles).reset_index(drop=True)\n",
    "    return quant_only\n",
    "\n",
    "quantifier_rating_table = data_by_quantifier(praise_data.copy())\n",
    "quantifier_rating_table.style\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae83cc4d",
   "metadata": {},
   "source": [
    "Now, we will calculate the rewards for the Quantifiers and the Reward Board. This is fairly straightforward: we distribute the tokens allocated for quantification proportionally to the number of praises quantified, and give all rewardboard members an equal cut.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5bfff6d3",
   "metadata": {},
   "source": [
    "Before we distribute the rewards, we must remove the quantifiers who didn't show up for this round even though they were drafted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "370e754e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# clear out the quantifiers who didn't give any rating (i.e. all scores are 0)\n",
    "quantifier_sum = quantifier_rating_table[['QUANT_ID','QUANT_VALUE']].groupby('QUANT_ID').sum()\n",
    "norating_quantifiers = quantifier_sum.loc[quantifier_sum['QUANT_VALUE']==0].index.tolist()\n",
    "norating_quantifiers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54c4677f",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "quantifier_rewards = pd.DataFrame(quantifier_rating_table[['QUANT_ID','QUANT_ADDRESS']].value_counts().reset_index().copy())\n",
    "\n",
    "quantifier_rewards = quantifier_rewards[~quantifier_rewards['QUANT_ID'].isin(norating_quantifiers)]\n",
    "\n",
    "quantifier_rewards = quantifier_rewards.rename(columns={ quantifier_rewards.columns[2]: \"NUMBER_OF_PRAISES\" }).reset_index(drop=True)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "total_praise_quantified = quantifier_rewards['NUMBER_OF_PRAISES'].sum()\n",
    "quantifier_rewards['TOKEN TO RECEIVE'] = quantifier_rewards['NUMBER_OF_PRAISES'] / total_praise_quantified  * NUMBER_OF_REWARD_TOKENS_FOR_QUANTIFIERS\n",
    "\n",
    "\n",
    "    \n",
    "quantifier_rewards.style"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06b7e71e",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "rewardboard_rewards = pd.DataFrame(rewardboard_addresses)\n",
    "rewardboard_rewards['TOKEN TO RECEIVE'] = NUMBER_OF_REWARD_TOKENS_FOR_REWARD_BOARD / len(rewardboard_rewards.index)\n",
    "rewardboard_rewards.style"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93b78fa3",
   "metadata": {},
   "source": [
    "Now we can merge them all into one table and save it, ready for distribution!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6871efe3",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#def prepare_total_data_chart(praise_rewards, sourcecred_rewards, quantifier_rewards, rewardboard_rewards):\n",
    "def prepare_total_data_chart(praise_rewards, quantifier_rewards, rewardboard_rewards):\n",
    "    \n",
    "    praise_rewards = praise_rewards.copy()[['USER IDENTITY', 'USER ADDRESS', 'TOKEN TO RECEIVE']].rename(columns = {'TOKEN TO RECEIVE':'PRAISE_REWARD'})\n",
    "    praise_rewards['USER ADDRESS'] = praise_rewards['USER ADDRESS'].str.lower()\n",
    "    \n",
    "    quantifier_rewards.rename(columns = {'QUANT_ADDRESS':'USER ADDRESS', 'QUANT_ID': 'USER IDENTITY', 'NUMBER_OF_PRAISES': 'NR_OF_PRAISES_QUANTIFIED', 'TOKEN TO RECEIVE':'QUANT_REWARD'}, inplace = True)\n",
    "    quantifier_rewards['USER ADDRESS'] = quantifier_rewards['USER ADDRESS'].str.lower()\n",
    "    \n",
    "    rewardboard_rewards.rename(columns = {'ID':'USER ADDRESS', 'TOKEN TO RECEIVE': 'REWARDBOARD_REWARD'}, inplace = True)\n",
    "    rewardboard_rewards['USER ADDRESS'] = rewardboard_rewards['USER ADDRESS'].str.lower()\n",
    "    \n",
    "    \n",
    "    final_allocations = pd.merge(rewardboard_rewards, quantifier_rewards , on=['USER ADDRESS','USER ADDRESS'], how='outer')\n",
    "    final_allocations = pd.merge(final_allocations, praise_rewards, left_on=['USER ADDRESS'], right_on=['USER ADDRESS'], how='outer')\n",
    "    \n",
    "    #now we can merge the IDs, replacing any missing values\n",
    "    final_allocations['USER IDENTITY_x']= final_allocations['USER IDENTITY_x'].combine_first(final_allocations['USER IDENTITY_y'])\n",
    "    final_allocations.rename(columns = {'USER IDENTITY_x': 'USER IDENTITY'},  inplace = True)\n",
    "    final_allocations.drop('USER IDENTITY_y', axis=1, inplace=True)\n",
    "    \n",
    "    \n",
    "    final_allocations['USER IDENTITY'].fillna('missing username', inplace = True)\n",
    "    final_allocations.fillna(0, inplace = True)\n",
    "    final_allocations['TOTAL TO RECEIVE'] = final_allocations['PRAISE_REWARD'] + final_allocations['QUANT_REWARD'] + final_allocations['REWARDBOARD_REWARD']\n",
    "   \n",
    "    \n",
    "    final_allocations = final_allocations.sort_values(by= 'TOTAL TO RECEIVE', ascending  = False).reset_index(drop=True)\n",
    "    \n",
    "    #put the columns into the desired order\n",
    "    final_allocations = final_allocations[['USER IDENTITY', 'USER ADDRESS', 'PRAISE_REWARD', 'QUANT_REWARD','NR_OF_PRAISES_QUANTIFIED', 'REWARDBOARD_REWARD', 'TOTAL TO RECEIVE']]\n",
    "    \n",
    "    \n",
    "    return final_allocations\n",
    "\n",
    "\n",
    "final_token_allocations = prepare_total_data_chart(praise_by_user.copy(), quantifier_rewards.copy(), rewardboard_rewards.copy())\n",
    "final_token_allocations.style\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c4534ac",
   "metadata": {},
   "source": [
    "### \"Glue\" relevant DataFrames to send to analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bb65ff9",
   "metadata": {},
   "outputs": [],
   "source": [
    "sb.glue(\"final_token_allocations\", final_token_allocations, 'pandas')\n",
    "sb.glue(\"rewardboard_rewards\", rewardboard_rewards, 'pandas')\n",
    "sb.glue(\"quantifier_rewards\", quantifier_rewards, 'pandas')\n",
    "sb.glue(\"quantifier_rating_table\", quantifier_rating_table, 'pandas')\n",
    "\n",
    "sb.glue(\"processed_praise\", processed_praise, 'pandas')\n",
    "sb.glue(\"praise_by_user\", praise_by_user, 'pandas')\n",
    "\n",
    "\n",
    "sb.glue(\"praise_distribution\", praise_distribution, 'pandas')\n",
    "sb.glue(\"quantifiers_per_praise\", quantification_settings[\"number_of_quantifiers_per_praise_receiver\"])\n",
    "sb.glue(\"distribution_name\", distribution_name)\n",
    "sb.glue(\"total_tokens_allocated\", total_tokens_allocated)\n",
    "sb.glue(\"praise_quantify_duplicate_praise_valuation\", quantification_settings['praise_quantify_duplicate_praise_valuation'])\n",
    "sb.glue(\"pseudonyms_used\", quantification_settings['praise_quantify_receiver_pseudonyms'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2c3bbca",
   "metadata": {},
   "source": [
    "### Save the distribution files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a59fd3a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_allocation_csv = final_token_allocations.to_csv(index=False)\n",
    "with open('final_praise_token_allocation.csv', 'w') as f:\n",
    "    f.write(final_allocation_csv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9811af2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#create \"transactions\" dist\n",
    "final_alloc_aragon = final_token_allocations[['USER ADDRESS', 'TOTAL TO RECEIVE']].copy()\n",
    "final_alloc_aragon['TOKEN SYMBOL'] = payout_token['token_name']\n",
    "final_alloc_aragon = final_alloc_aragon[final_alloc_aragon['USER ADDRESS'] != \"missing user address\"]\n",
    "final_alloc_aragon = final_alloc_aragon.to_csv(sep=',', index=False, header=False)\n",
    "with open('praise_aragon_distribution.csv', 'w') as f:\n",
    "    f.write(final_alloc_aragon)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79d6252d",
   "metadata": {},
   "outputs": [],
   "source": [
    "praise_reward_export = praise_distribution.to_csv(index=False)\n",
    "with open('extended_praise_data.csv', 'w') as f:\n",
    "    f.write(praise_reward_export)"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Tags",
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  },
  "vscode": {
   "interpreter": {
    "hash": "fb35c82b16c4bb7513c452d8c44c32564b970d0024820e7dc228e854f7e54d03"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
