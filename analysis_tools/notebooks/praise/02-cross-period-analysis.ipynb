{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fe4a709",
   "metadata": {
    "tags": [
     "parameters"
    ]
   },
   "outputs": [],
   "source": [
    "input_files = {}\n",
    "distribution_parameters = {}\n",
    "#WARNING: When re-running the notebook for audit, change the injected path below to \"./output_praiseDist_test.ipynb\"\n",
    "#then go to \"Cell > Run all\" -- This only works for the notebook in \n",
    "#\"distribution_results/round ?/results/analysis_outputs/output_general_RAD_report.ipynb\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "677d3b44",
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    categ_keywords = distribution_parameters['categorization_settings']['type_keywords']\n",
    "except:\n",
    "    #categ_keywords = {'attendance':'join|attend|show up|participat','discussion':'question|ask|discuss|discussion','work':'help|work|design|make|write|hack|edit','lead':'host|lead|initiate|form|organize|steward','share':'share|spread','twitter':'twitter|tweet','hack':'hack|test','general':'support|awesome','IRL':'trip|conference'}\n",
    "    categ_keywords = {'attendance':'join|attend|show up|coming to','discussion':'question|ask|discuss|discussion|insight|participat|feedback|observations|forum|comment|share','work':'work|writing|hack|edit|studying|research|drafting|mediat|recording|taking notes|note taking|develop|analysis','lead':'host|lead|initiat|organizing|organizer|steward|forming|facilitate|managing','share':'share|spread','social media':'twitter|tweet|retweet|socials|social media','hardskills':'design|bug fixes|deploy|prototype|coding|python|javascript|solidity|data science','self-care':'vacation|time off|time-off|holiday|sabbatical|day off','IRL':'trip|DAOist|ETHcc|barcelona|denver|paris|amsterdam|colombia'}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5b95fea",
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    NUMBER_OF_WEEKS = distribution_parameters[\"cross_period_settings\"][\"cross_period_week_num\"]\n",
    "    STEP_SIZE = distribution_parameters[\"cross_period_settings\"][\"cross_period_step_size\"]\n",
    "except:\n",
    "    NUMBER_OF_WEEKS = 4\n",
    "    STEP_SIZE = 1\n",
    "    print(f'Using default time period: the most recent {NUMBER_OF_WEEKS} weeks, looking into every {STEP_SIZE} week.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2546bfec",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import os\n",
    "import sys\n",
    "\n",
    "import pandas as pd \n",
    "import numpy as np \n",
    "from collections import OrderedDict\n",
    "from natsort import natsorted\n",
    "from datetime import datetime, timedelta\n",
    "\n",
    "import holoviews as hv\n",
    "from holoviews import opts\n",
    "import plotly.graph_objects as go\n",
    "import plotly.express as px\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import base64\n",
    "from IPython.display import HTML\n",
    "from IPython.display import Markdown as md\n",
    "\n",
    "import scrapbook as sb\n",
    "\n",
    "from re import search\n",
    "\n",
    "#adding directories for the analysis tool. this is mainly for when we re-run the notebook \n",
    "dir2 = os.path.abspath('../../../../../rad/analysis_tools')\n",
    "dir1 = os.path.dirname(dir2)\n",
    "if not dir1 in sys.path: sys.path.append(dir1)\n",
    "from analysis_tools.module_libraries import praise_analysis_module as praise_tools\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8bc18fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_into_weeks(data, num_weeks, step_size):\n",
    "    data = data.sort_values(by='DATE', ascending = True).reset_index()\n",
    "    data[\"DATE\"] = pd.to_datetime(data[\"DATE\"])\n",
    "    \n",
    "    first_date = pd.to_datetime(data.at[len(data.index) - 1, \"DATE\"]) - timedelta(weeks=(num_weeks))\n",
    "    \n",
    "    roundname_list = []\n",
    "\n",
    "    rounds_df = {}\n",
    "    for week in range(0, num_weeks, step_size):\n",
    "        week_id = \"Week \" + str(week+1)\n",
    "        roundname_list.append(week_id)\n",
    "        rounds_df[week_id]= []\n",
    "        start_date = first_date + timedelta(weeks=(week))\n",
    "        end_date = first_date + timedelta(weeks=(week+step_size))\n",
    "        \n",
    "        rounds_df[week_id] =  data.loc[(data['DATE'] >= start_date) & (data['DATE'] <= end_date)]\n",
    "\n",
    "                \n",
    "    return rounds_df, roundname_list\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c838ec1",
   "metadata": {},
   "outputs": [],
   "source": [
    "datadir = input_files[\"cross_period_root\"]\n",
    "foldername_list = natsorted(os.listdir(datadir))\n",
    "\n",
    "allrounds_df = []\n",
    "allrounds_finaldist = []\n",
    "\n",
    "rounds = 0\n",
    "for round_name in foldername_list:\n",
    "    if not os.path.isdir(f'{datadir}/{round_name}'):\n",
    "        foldername_list.remove(round_name)\n",
    "        continue\n",
    "    rounds+=1\n",
    "    round_df = pd.read_csv(f'{datadir}/{round_name}/distribution_results/raw_csv_exports/praise_outliers.csv')\n",
    "    dist_df = pd.read_csv(f'{datadir}/{round_name}/distribution_results/raw_csv_exports/extended_praise_data.csv')\n",
    "\n",
    "    \n",
    "    for index, row in round_df.iterrows():\n",
    "        #print(row)\n",
    "        row['QUANT ROUND']=round_name\n",
    "        allrounds_df.append(row)\n",
    "    for index, row in dist_df.iterrows():\n",
    "        row['QUANT_ROUND']=round_name\n",
    "        allrounds_finaldist.append(row)\n",
    "        \n",
    "    \n",
    "allrounds_df = pd.DataFrame(allrounds_df)\n",
    "allrounds_finaldist = pd.DataFrame(allrounds_finaldist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cf13e5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "allrounds_df.drop(\"index\", axis =1,  inplace=True)\n",
    "allrounds_df.fillna(value={\"QUANTIFIER 4 USERNAME\": \"None\"}, inplace=True)\n",
    "master_allrounds = allrounds_df.copy()\n",
    "week_df, roundname_list = split_into_weeks(allrounds_df, NUMBER_OF_WEEKS, STEP_SIZE)\n",
    "allrounds_df = week_df\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fef1112",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "finaldist_weekly, roundname_list = split_into_weeks(allrounds_finaldist, NUMBER_OF_WEEKS, STEP_SIZE)\n",
    "for period in roundname_list:\n",
    "\n",
    "    period_dist = finaldist_weekly[period].copy()\n",
    "    period_dist = period_dist[['TO USER ACCOUNT ID', 'DATE', 'TO USER ACCOUNT', 'TOKEN TO RECEIVE']].copy().groupby(['TO USER ACCOUNT ID', 'TO USER ACCOUNT',]).agg('sum').reset_index()\n",
    "    period_dist.rename(columns = {'TOKEN TO RECEIVE': 'PRAISE REWARDS'}, inplace = True)\n",
    "    \n",
    "    period_dist = period_dist.sort_values(by='PRAISE REWARDS', ascending=False).reset_index()\n",
    "    period_dist.drop(\"index\", axis =1,  inplace=True)\n",
    "    \n",
    "    finaldist_weekly[period] = period_dist\n",
    "    \n",
    "allrounds_finaldist = finaldist_weekly\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "326ca887",
   "metadata": {},
   "source": [
    "# Cross-Period Analysis Report\n",
    "This report aims to offer a perspective on the activity inside the praise system over several rounds."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61409884",
   "metadata": {},
   "outputs": [],
   "source": [
    "md(f\"This report will cover <b>{NUMBER_OF_WEEKS}</b> weeks, divided into blocks of <b>{STEP_SIZE}</b> weeks each.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60167805",
   "metadata": {},
   "source": [
    "# General Statistics\n",
    "The full range will be subdivided into the following periods:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0896c63",
   "metadata": {},
   "outputs": [],
   "source": [
    "round_stats = pd.DataFrame(index=allrounds_df.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "308a3681",
   "metadata": {},
   "outputs": [],
   "source": [
    "round_stats['period_start_time'] =  [str(allrounds_df[round_name]['DATE'].min())[:10] for round_name in roundname_list]\n",
    "round_stats['period_end_time'] =  [str(allrounds_df[round_name]['DATE'].max())[:10] for round_name in roundname_list]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d18bc3d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "round_stats"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1be6baf2",
   "metadata": {},
   "source": [
    "## Praise Involvement"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "822d322d",
   "metadata": {},
   "source": [
    "### How much praise? \n",
    "This graph shows the trend of total number of praise instances across time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e24a823",
   "metadata": {},
   "outputs": [],
   "source": [
    "round_stats['total_praise'] = [len(allrounds_df[round_name]) for round_name in roundname_list]\n",
    "px.line(round_stats,x='period_start_time',y='total_praise',markers=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3eef7b85",
   "metadata": {},
   "source": [
    "### How many people give and receive praise?\n",
    "Counting the unique ID of praise givers and receivers, we can visualize the change across time. In the figure, the blue line represents the amount of praise receivers and thered line the amount of givers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06c0a647",
   "metadata": {},
   "outputs": [],
   "source": [
    "round_stats['total_praise_receiver'] = [len(np.unique(allrounds_df[round_name]['TO USER ACCOUNT'])) for round_name in roundname_list]\n",
    "round_stats['total_praise_giver'] = [len(np.unique(allrounds_df[round_name]['FROM USER ACCOUNT'])) for round_name in roundname_list]\n",
    "\n",
    "px.line(round_stats,x='period_start_time',y=['total_praise_receiver','total_praise_giver'],markers=True,title='total praise giver and receiver')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc4ca3a0",
   "metadata": {},
   "source": [
    "## Quantifier Involvement\n",
    "Showing how many quantifiers are involved in each round."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68eacac2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#this metric has to be kept in a per-round basis, since quntifiers are assigned in that rythm\n",
    "try:\n",
    "    quant_stats = pd.DataFrame()\n",
    "    quant_stats[\"quant_round\"] = foldername_list\n",
    "    quant_stats['total_quantifier'] = [len(np.unique(master_allrounds[master_allrounds['QUANT ROUND'] == round_name].filter(like='QUANTIFIER'))) for round_name in foldername_list]\n",
    "    px.line(quant_stats,x=\"quant_round\",y=['total_quantifier'],markers=True,title='total quantifiers')\n",
    "except:\n",
    "    print(\"Exception encountered while processing quantifiers\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "148db817",
   "metadata": {},
   "source": [
    "### Quantifier trend"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8d19bfe",
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    pr=praise_tools.praise_quantifier(master_allrounds)\n",
    "except:\n",
    "    print(\"Exception encountered while processing quantifiers\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e4ae456",
   "metadata": {},
   "source": [
    "### average score displacement: tendency to under/over-estimate?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec886aa7",
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    pr.plot_mean_displacement()\n",
    "except:\n",
    "    print(\"Exception encountered while processing quantifiers\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36527731",
   "metadata": {},
   "source": [
    "### average score correlation coefficient: how much do i agree with other people?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8121c07",
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    pr.plot_coefficient()\n",
    "except:\n",
    "    print(\"Exception encountered while processing quantifiers\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0bd05bfc",
   "metadata": {},
   "source": [
    "# System Health Evaluation"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "526f8477",
   "metadata": {},
   "source": [
    "\n",
    "## Number of new Giveth members involved in praise (either giving or receiving)\n",
    "Counting the round-by-round change of unique IDs being either praise giver or praise receiver."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef93ad3b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "try:\n",
    "    round_stats['round_user_list'] = [set(np.unique(allrounds_df[round_name].filter(like='ACCOUNT')))\n",
    "            .union(set(np.unique(allrounds_df[round_name].filter(like='QUANTIFIER')))) for round_name in roundname_list]\n",
    "except:\n",
    "    print(\"Error in quantifiers, skipping them for analysis\")\n",
    "    round_stats['round_user_list'] = [set(np.unique(allrounds_df[round_name].filter(like='ACCOUNT'))) for round_name in roundname_list]\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d52ab3fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "round_stats['round_user_new'] = [np.nan]+ [len(round_stats.loc[roundname_list[kr+1],'round_user_list'] - \n",
    "                                         round_stats.loc[roundname_list[kr],'round_user_list']) for kr in np.arange(len(roundname_list)-1)]\n",
    "\n",
    "round_stats['round_user_left'] = [np.nan]+[len(round_stats.loc[roundname_list[kr],'round_user_list'] - \n",
    "                                         round_stats.loc[roundname_list[kr+1],'round_user_list']) for kr in np.arange(len(roundname_list)-1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d713bd21",
   "metadata": {},
   "outputs": [],
   "source": [
    "round_stats['round_net_user_diff']=round_stats['round_user_new']-round_stats['round_user_left']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b60e4c03",
   "metadata": {},
   "source": [
    "The blue line represents new IDs in this round, the red line represents IDs that are absent in this round but were present in the last round. The green line shows the net difference, with above 0 meaning more people joined praise than people left and below 0 meaning the opposite."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a688024",
   "metadata": {},
   "outputs": [],
   "source": [
    "px.line(round_stats,x='period_start_time',y=['round_user_new','round_user_left','round_net_user_diff'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc6e2a29",
   "metadata": {},
   "source": [
    "## Distribution Equality"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "699f3461",
   "metadata": {},
   "source": [
    "### Nakamoto Coefficient\n",
    "\n",
    "The Nakamato Coefficient is defined as the smallest number of accounts who control at least 50% of the resource. Although its significance relates to the prospect of a 51% attack on a network, which may not be relevant in our context, we can still use it as an intuitive measure of how many individuals received the majority of rewards.\n",
    "\n",
    "Bigger coefficient means more distributed (i.e. needs more people to pass 50%), smaller means more concentrated power. The number should always be an integer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50215949",
   "metadata": {},
   "outputs": [],
   "source": [
    "def nakamoto_coeff(x, key):\n",
    "    value_sum= x[key].sum()\n",
    "    x['PERCENTAGE'] = x[key] / value_sum\n",
    "    sorted_x = x.sort_values(by='PERCENTAGE', ascending=False)\n",
    "    tot_sum = np.array(sorted_x['PERCENTAGE'].cumsum())\n",
    "    try:\n",
    "        winner = np.array([k for k in range(len(tot_sum))\n",
    "                          if tot_sum[k] > 0.5]).min() + 1\n",
    "    except:\n",
    "        winner = -1\n",
    "    return winner\n",
    "def nakamoto_coeff_ratio(x, key):\n",
    "    winner = nakamoto_coeff(x, key)\n",
    "    ratio = winner / len(x)\n",
    "    return ratio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a754f44",
   "metadata": {},
   "outputs": [],
   "source": [
    "round_stats['nakamoto']  = [nakamoto_coeff(allrounds_finaldist[round_name],'PRAISE REWARDS') for round_name in roundname_list]\n",
    "round_stats['nakamoto_ratio']= [nakamoto_coeff_ratio(allrounds_finaldist[round_name],'PRAISE REWARDS') for round_name in roundname_list]\n",
    "px.line(round_stats,x='period_start_time',y='nakamoto',markers=True,title='Minimum number of people receiving 50% of total rewards')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3c5e204",
   "metadata": {},
   "outputs": [],
   "source": [
    "px.line(round_stats,x='period_start_time',y='nakamoto_ratio',markers=True,title='Ratio of people accumulating 50% of total rewards in relation to total number of receivers in that round')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9071942b",
   "metadata": {},
   "source": [
    "# Categorizing praise based on the praise reason"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "215d7590",
   "metadata": {},
   "outputs": [],
   "source": [
    "def categorize_praise(master_df,categ_keywords,save_csv=False):\n",
    "    # clean the data\n",
    "    allpraise_df = master_df[['REASON','AVG SCORE','TO USER ACCOUNT','DATE']]\n",
    "    nonzerodf = allpraise_df.loc[(allpraise_df['AVG SCORE']>0) * (~allpraise_df['REASON'].isnull())]\n",
    "    #print(f'among {len(allpraise_df)} praises, {len(nonzerodf)} have scores more than 0. Only include them')\n",
    "    nonzerodf.insert(0,'CLEANED REASON',nonzerodf['REASON'].apply(praise_tools.clean_praise))\n",
    "\n",
    "    # do categorization\n",
    "    allcategs = []\n",
    "    for kr,row in nonzerodf.iterrows():\n",
    "        category = []\n",
    "        praise = row['CLEANED REASON'].lower()\n",
    "        for praise_type,keywords in categ_keywords.items():\n",
    "            if search(keywords,praise):\n",
    "                category.append(praise_type)\n",
    "        if len(category):\n",
    "            allcategs.append(category)\n",
    "        else:\n",
    "            allcategs.append(np.nan)\n",
    "    category_df = pd.concat([nonzerodf.reset_index(), pd.DataFrame({\"category\":allcategs})],axis=1)\n",
    "    if save_csv:\n",
    "        # save the categorization into csv; there's a file including only uncategorized praise\n",
    "        category_df.loc[category_df['category'].isnull()].to_csv('uncateogrized.csv')\n",
    "        print(f\"{sum(category_df['category'].isnull())} out of {len(category_df)} praises uncategorized\")\n",
    "        category_df.to_csv('categorized_praise.csv')\n",
    "    \n",
    "    #When there's a praise matching more than one category, they will be counted multiple times\n",
    "    #organize the data for easier analysis\n",
    "    categ_praise_scores = {k:[] for k in categ_keywords.keys()}\n",
    "\n",
    "    for kr,row in category_df.iterrows():\n",
    "        if type(row['category']) is list:\n",
    "            for key in row['category']:\n",
    "                categ_praise_scores[key] += [{'praise':row['REASON'],'avg_score':row['AVG SCORE'],'receiver':row['TO USER ACCOUNT'],'date':row['DATE']}]\n",
    "    categ_praise_scores_df = dict.fromkeys(categ_keywords.keys())\n",
    "    for key, item in categ_praise_scores.items():\n",
    "        categ_praise_scores_df[key]= pd.DataFrame(item)\n",
    "    return categ_praise_scores_df,category_df\n",
    "def get_categ_stats(df,keywords):\n",
    "    categ_stats = dict.fromkeys(keywords.keys())\n",
    "    for categ in keywords.keys():\n",
    "        if len(df[categ])==0: # empty category, skip this\n",
    "            continue\n",
    "        categ_stats[categ] = {'mean':np.mean(df[categ]['avg_score']),\n",
    "                                'max':np.max(df[categ]['avg_score']),\n",
    "                                'min':np.min(df[categ]['avg_score'])}\n",
    "        \n",
    "    categ_stats_df = pd.DataFrame(categ_stats)\n",
    "    categ_stats_df = categ_stats_df.transpose().sort_values(by='mean')\n",
    "    return categ_stats_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3277c78f",
   "metadata": {},
   "outputs": [],
   "source": [
    "categ_praise_df,category_df = categorize_praise(master_allrounds,categ_keywords,save_csv=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4d4b99a",
   "metadata": {},
   "source": [
    "##  the average, min, max score of each category\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7c6dbbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "categ_stats = get_categ_stats(categ_praise_df,categ_keywords)\n",
    "categ_stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6585784",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot it out\n",
    "categ_stats = get_categ_stats(categ_praise_df,categ_keywords)\n",
    "categ_stats['max-mean'] = categ_stats['max'] - categ_stats['mean']\n",
    "categ_stats['mean-min'] = categ_stats['mean'] - categ_stats['min']\n",
    "\n",
    "fig=px.bar(categ_stats,y='mean',error_y='max-mean',error_y_minus='mean-min',title='average score of each category')\n",
    "fig.show()\n",
    "md('errorbars mark the maximum average score for this category')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e850a9cd",
   "metadata": {},
   "source": [
    "## Top 3 highest scored praise in each category\n",
    "A convenient way to check if the categorization keywords are reasonable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cea8ccfa",
   "metadata": {},
   "outputs": [],
   "source": [
    "mdtext = ''\n",
    "for categ in categ_praise_df.keys():\n",
    "    categ_name = '# '+categ + '\\n'\n",
    "    toppraise = categ_praise_df[categ].sort_values(by='avg_score',ascending=False).iloc[:3]\n",
    "    top3_table= (f\"\\\n",
    "| Avg. score | To | Reason | Date |\\n \\\n",
    "|:-----------|----|--------|-----:|\\n\")\n",
    "    for kr,row in toppraise.iterrows():\n",
    "        to_user = row['receiver']\n",
    "        reason = row['praise']\n",
    "        score = row['avg_score']\n",
    "        date = row['date'][:10]\n",
    "                    \n",
    "        top3_table += (f\"| {score} | {to_user} | {reason} | {date} |\\n\")\n",
    "        #print(f'Praise score average: {score}\\nFROM {from_user} TO {to_user},reason:\\n{reason}\\n')\n",
    "    mdtext += categ_name + top3_table    \n",
    "md(mdtext)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30deb699",
   "metadata": {},
   "source": [
    "## trend across time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba09b1d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_score_dict = {k:[] for k in categ_keywords.keys()}\n",
    "praise_num_dict = {k:[] for k in categ_keywords.keys()}\n",
    "for round_name in roundname_list:\n",
    "    round_categ_praise_score_df,_ = categorize_praise(allrounds_df[round_name],categ_keywords)\n",
    "    round_categ_stats = get_categ_stats(round_categ_praise_score_df,categ_keywords)\n",
    "    for key in mean_score_dict.keys():\n",
    "        try:\n",
    "            mean_score_dict[key].append(float(round_categ_stats['mean'].loc[key]))\n",
    "        except: \n",
    "            mean_score_dict[key].append(0.0)\n",
    "        praise_num_dict[key].append(len(round_categ_praise_score_df[key]))\n",
    "for key in mean_score_dict.keys():  \n",
    "    round_stats[key+'_avg_score']=mean_score_dict[key]\n",
    "    round_stats[key+'_praise_num']=praise_num_dict[key]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86244914",
   "metadata": {},
   "outputs": [],
   "source": [
    "px.line(round_stats.filter(like='num'),title='number of praise in each category, across time')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94a4fd3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "px.line(round_stats.filter(like='_avg_score'),title='mean score of each category, across time')"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Tags",
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  },
  "vscode": {
   "interpreter": {
    "hash": "fb35c82b16c4bb7513c452d8c44c32564b970d0024820e7dc228e854f7e54d03"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
